{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucia\\miniconda3\\envs\\diffusion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import cached_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env create by  req file\n",
    "\n",
    "pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html --trusted-host  download.pytorch.orgreq\n",
    "\n",
    "conda env create -f req.yml\n",
    "\n",
    "conda env update --file req.yml --prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucia\\miniconda3\\envs\\diffusion\\lib\\site-packages\\torchmetrics\\utilities\\imports.py:22: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import diffusers\n",
    "import transformers\n",
    "import cv2\n",
    "import einops\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.0.0+cpu\n",
      "Diffusers Version: 0.15.0\n",
      "Transformers Version: 4.28.0\n",
      "OpenCV Version: 4.7.0\n",
      "Einops Version: 0.6.1\n",
      "OmegaConf Version: 2.3.0\n",
      "PyTorch Lightning Version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Diffusers Version:\", diffusers.__version__)\n",
    "print(\"Transformers Version:\", transformers.__version__)\n",
    "print(\"OpenCV Version:\", cv2.__version__)\n",
    "print(\"Einops Version:\", einops.__version__)\n",
    "print(\"OmegaConf Version:\", omegaconf.__version__)\n",
    "print(\"PyTorch Lightning Version:\", pl.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install after req.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install torchvision==0.15.1\n",
    "\n",
    "line 55 main.py\n",
    "\n",
    "#model_path = \"/nethome/atena_projetos/cym7/models/stable-diffusion-v1-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running Rysen 7 8900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorr\n",
    "ect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for \n",
    "the `scheduler/scheduler_config.json` file                                                                                                                   \n",
    "  deprecate(\"steps_offset!=1\", \"1.0.0\", deprecation_message, standard_warn=False)                                                                            \n",
    "# 1. invert references - Time elapsed: 103.29 seconds                                                                                                        \n",
    "input text embeddings : torch.Size([1, 77, 768])                                                                                                             \n",
    "latents shape:  torch.Size([1, 4, 64, 64])                                                                                                                   \n",
    "Valid timesteps:  tensor([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181, 201, 221, 241, 261,                                                              \n",
    "        281, 301, 321, 341, 361, 381, 401, 421, 441, 461, 481, 501, 521, 541,                                                                                \n",
    "        561, 581, 601, 621, 641, 661, 681, 701, 721, 741, 761, 781, 801, 821,                                                                                \n",
    "        841, 861, 881, 901, 921, 941, 961, 981])                                                                                                             \n",
    "DDIM Inversion: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [03:41<00:00,  4.44s/it] \n",
    "# 2. invert target to get IR - Time elapsed: 224.62 seconds                                                                                                  \n",
    "input text embeddings : torch.Size([1, 77, 768])                                                                                                             \n",
    "latents shape:  torch.Size([1, 4, 64, 64])                                                                                                                   \n",
    "Valid timesteps:  tensor([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181, 201, 221, 241, 261,                                                              \n",
    "        281, 301, 321, 341, 361, 381, 401, 421, 441, 461, 481, 501, 521, 541,                                                                                \n",
    "        561, 581, 601, 621, 641, 661, 681, 701, 721, 741, 761, 781, 801, 821,                                                                                \n",
    "        841, 861, 881, 901, 921, 941, 961, 981])                                                                                                             \n",
    "DDIM Inversion: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [03:12<00:00,  3.86s/it] \n",
    "MasaCtrl at denoising steps:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]                                                         \n",
    "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]                                                                                                          \n",
    "ref_num =  1                                                                                                                                                 \n",
    "# 3. inversion target with IR- Time elapsed: 195.70 seconds                                                                                                  \n",
    "input text embeddings : torch.Size([1, 77, 768])                                                                                                             \n",
    "latents shape:  torch.Size([1, 4, 64, 64])                                                                                                                   \n",
    "Valid timesteps:  tensor([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181, 201, 221, 241, 261,                                                              \n",
    "        281, 301, 321, 341, 361, 381, 401, 421, 441, 461, 481, 501, 521, 541,                                                                                \n",
    "        561, 581, 601, 621, 641, 661, 681, 701, 721, 741, 761, 781, 801, 821,                                                                                \n",
    "        841, 861, 881, 901, 921, 941, 961, 981])                                                                                                             \n",
    "DDIM Inversion: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [07:45<00:00,  9.30s/it] \n",
    "MasaCtrl at denoising steps:  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]       \n",
    "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]                                                                                                          \n",
    "ref_num =  1                                                                                                                                                 \n",
    "# 4. sampling to get result_01 - Time elapsed: 467.95 seconds                                                                                                \n",
    "input text embeddings : torch.Size([2, 77, 768])                                                                                                             \n",
    "DDIM Sampler:  62%|█████████████████████████████████████████████████████████████████                                        | 31/50 [04:08<02:43,  8.61s/it] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
